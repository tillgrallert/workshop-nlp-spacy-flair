{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ac64c77-33f5-405c-94c2-a2addc25105c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# about\n",
    "\n",
    "Dieses Notebook dient der Übung des bisher gelernten. Es sollen Daten mit SpaCy exploriert werden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72bbc9-79e7-4027-bc5a-baa6b7b8ba4b",
   "metadata": {},
   "source": [
    "## load libraries / packages and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c60e244d-29cf-491e-bc5e-a34b74db8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import spacy\n",
    "# load nlp model\n",
    "nlp_de = spacy.load('de_core_news_md') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c460e-8d7b-4935-9791-2ed10750756a",
   "metadata": {},
   "source": [
    "## load data\n",
    "\n",
    "- as basic text string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616ed9db-6e5e-45e5-9c80-34b3cf67b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sample = '''Paris Hilton reiste nach Paris um im dortigen Hilton zu übernachten'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1008dc-a6b5-4db4-bf6d-20bd07b84bd9",
   "metadata": {},
   "source": [
    "- from file: note that the input data type for the NLP tagger is a string, which means that the file contents must be read and converted into a string with the `str()` function\n",
    "    - note that there is a maximum length of individual strings\n",
    "    - note that the encoding should be specified as best practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7330bc35-b0a4-41c8-a556-73ab94975df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_sample = open(\"../data/sample.txt\", \"a\")\n",
    "with open(\"../data/sample.txt\", \"r\", encoding = \"utf8\") as file:\n",
    "    file_sample = file.read()\n",
    "#print(file_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e971323-e91e-4ff8-9204-512f481956c8",
   "metadata": {},
   "source": [
    "# tag data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f61a0e1a-e658-4d0a-ad9c-27ee91c7548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sample_text = nlp_de(text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e20c1c0-1e21-4336-b6d4-506ad04fae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sample_file = nlp_de(file_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1f03e02-03ec-4eba-8c33-e7103a6e8f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: \n",
      "\n",
      "\n",
      "  \n",
      "              Lemmata: \n",
      "\n",
      "\n",
      " \n",
      "              POS: SPACE\n",
      "              explain POS: space\n",
      "              TAG: _SP\n",
      "              explain TAG: whitespace\n",
      "              Dependency: dep\n",
      "              explain Dependency: unclassified dependent\n",
      "              Entity: \n",
      "Token: “  \n",
      "              Lemmata: “ \n",
      "              POS: PUNCT\n",
      "              explain POS: punctuation\n",
      "              TAG: $(\n",
      "              explain TAG: other sentence-internal punctuation mark\n",
      "              Dependency: punct\n",
      "              explain Dependency: punctuation\n",
      "              Entity: \n",
      "Token: Oberleutnant  \n",
      "              Lemmata: Oberleutnant \n",
      "              POS: NOUN\n",
      "              explain POS: noun\n",
      "              TAG: NN\n",
      "              explain TAG: noun, singular or mass\n",
      "              Dependency: sb\n",
      "              explain Dependency: subject\n",
      "              Entity: \n",
      "Token: möchten  \n",
      "              Lemmata: mögen \n",
      "              POS: AUX\n",
      "              explain POS: auxiliary\n",
      "              TAG: VMFIN\n",
      "              explain TAG: finite verb, modal\n",
      "              Dependency: ROOT\n",
      "              explain Dependency: None\n",
      "              Entity: \n",
      "Token: sofort  \n",
      "              Lemmata: sofort \n",
      "              POS: ADV\n",
      "              explain POS: adverb\n",
      "              TAG: ADV\n",
      "              explain TAG: adverb\n",
      "              Dependency: mo\n",
      "              explain Dependency: modifier\n",
      "              Entity: \n",
      "Token: zu  \n",
      "              Lemmata: zu \n",
      "              POS: ADP\n",
      "              explain POS: adposition\n",
      "              TAG: APPR\n",
      "              explain TAG: preposition; circumposition left\n",
      "              Dependency: mo\n",
      "              explain Dependency: modifier\n",
      "              Entity: \n",
      "Token: Herrn  \n",
      "              Lemmata: Herrn \n",
      "              POS: NOUN\n",
      "              explain POS: noun\n",
      "              TAG: NN\n",
      "              explain TAG: noun, singular or mass\n",
      "              Dependency: nk\n",
      "              explain Dependency: noun kernel element\n",
      "              Entity: PER\n",
      "Token: Hauptmann  \n",
      "              Lemmata: Hauptmann \n",
      "              POS: NOUN\n",
      "              explain POS: noun\n",
      "              TAG: NE\n",
      "              explain TAG: proper noun\n",
      "              Dependency: pnc\n",
      "              explain Dependency: proper noun component\n",
      "              Entity: PER\n",
      "Token: Kr  \n",
      "              Lemmata: Kr \n",
      "              POS: PROPN\n",
      "              explain POS: proper noun\n",
      "              TAG: NE\n",
      "              explain TAG: proper noun\n",
      "              Dependency: nk\n",
      "              explain Dependency: noun kernel element\n",
      "              Entity: \n",
      "Token: .  \n",
      "              Lemmata: . \n",
      "              POS: PUNCT\n",
      "              explain POS: punctuation\n",
      "              TAG: $.\n",
      "              explain TAG: sentence-final punctuation mark\n",
      "              Dependency: punct\n",
      "              explain Dependency: punctuation\n",
      "              Entity: \n"
     ]
    }
   ],
   "source": [
    "doc = doc_sample_file\n",
    "for token in doc[10:20]:\n",
    "    print(f'''Token: {token}  \n",
    "              Lemmata: {token.lemma_} \n",
    "              POS: {token.pos_}\n",
    "              explain POS: {spacy.explain(token.pos_)}\n",
    "              TAG: {token.tag_}\n",
    "              explain TAG: {spacy.explain(token.tag_)}\n",
    "              Dependency: {token.dep_}\n",
    "              explain Dependency: {spacy.explain(token.dep_)}\n",
    "              Entity: {token.ent_type_}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f9df2a-c749-431f-a4a2-efa7648a538b",
   "metadata": {},
   "source": [
    "# check for named entites\n",
    "## Personen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "647a8613-37b5-4fca-839b-bc2826fee539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herrn PER\n",
      "Hauptmann PER\n",
      "Sch PER\n",
      ". PER\n",
      "Szegedin PER\n",
      "Szegedin PER\n",
      "Szegedin PER\n",
      "Szegedin PER\n",
      "v. PER\n",
      "R. PER\n",
      "Zögernd PER\n",
      "v. PER\n",
      "W. PER\n",
      "Pußta PER\n",
      "“ PER\n",
      ". PER\n",
      "Nisch PER\n",
      "Landfuhrwerke PER\n",
      "Buuardschik PER\n",
      "Tepe PER\n",
      "Bulgarisch PER\n",
      ". PER\n",
      "Nie PER\n",
      "Wau PER\n",
      ", PER\n",
      "wau PER\n",
      "” PER\n",
      "Konstantinopel PER\n",
      "K. PER\n",
      "ablaufen PER\n",
      ": PER\n",
      "Scheich PER\n",
      "’s PER\n",
      "Tunnel PER\n",
      "Eskischekir PER\n",
      "Motorpflug PER\n",
      "Xenophon PER\n",
      "Friedrich PER\n",
      "Barbarossa PER\n",
      "Kamelkarawanen PER\n",
      "Tscham PER\n",
      "Alan PER\n",
      "Han PER\n",
      "Tscham PER\n",
      "Alan PER\n",
      "ver PER\n",
      "zeichnen PER\n",
      ". PER\n",
      "Alexander PER\n",
      "der PER\n",
      "Große PER\n",
      "Gottfried PER\n",
      "von PER\n",
      "Bouillon PER\n",
      "Ibrahim PER\n",
      "Paschas PER\n",
      "Befesti PER\n",
      "Hans PER\n",
      "Hans PER\n",
      "Ma- PER\n",
      "mure PER\n",
      "Jslahie PER\n",
      "Gülek PER\n",
      "Gülek PER\n",
      "Paulus PER\n",
      "Alexander PER\n",
      "des PER\n",
      "Großen PER\n",
      "gefährlichem PER\n",
      "Bad PER\n",
      "Gülek PER\n",
      "H. PER\n",
      "zusammentraf PER\n",
      ". PER\n",
      "Mamure PER\n",
      "Amanus PER\n",
      "Goltz PER\n",
      "Tschan PER\n",
      "Alan PER\n",
      "\n",
      "  PER\n",
      "in PER\n",
      "v. PER\n",
      "Mücke PER\n",
      "Sven PER\n",
      "Hedin PER\n",
      "Bienenkörbe PER\n",
      "ben PER\n",
      "will PER\n",
      "Hermon PER\n",
      "“ PER\n",
      ". PER\n",
      "Hermon PER\n",
      "Dera PER\n",
      "’ PER\n",
      "at PER\n",
      "Schroff PER\n",
      "Hell PER\n",
      "Weiber PER\n",
      "Nie PER\n",
      "v. PER\n",
      "K. PER\n",
      "v. PER\n",
      "K. PER\n",
      "Birseba PER\n",
      "Himmels PER\n",
      ". PER\n",
      "v. PER\n",
      "K PER\n",
      "> PER\n",
      "v. PER\n",
      "K. PER\n",
      "Jahrtausendelang PER\n",
      "Mondaufgang PER\n",
      "Towsend PER\n",
      "Decka PER\n",
      "Rückreise PER\n",
      ": PER\n",
      "Also PER\n",
      "Sauls PER\n",
      "Rebekkas PER\n",
      "Abraham PER\n",
      "Geburtskirche PER\n",
      "“ PER\n",
      "Jesus PER\n",
      "Christus PER\n",
      "von PER\n",
      "der PER\n",
      "Jungfrau PER\n",
      "Maria PER\n",
      "geboren PER\n",
      ". PER\n",
      "Blendender PER\n",
      "Sonnenschein PER\n",
      "Schmuck PER\n",
      "Grabe PER\n",
      "Schöner PER\n",
      "Christus PER\n",
      "Abraham PER\n",
      "Sohn PER\n",
      "Kana PER\n",
      "Jakobs PER\n",
      "” PER\n",
      "v. PER\n",
      "K. PER\n",
      "Amanus PER\n",
      "Tscham PER\n",
      "Alan PER\n",
      "Kurs PER\n",
      "Schneid PER\n",
      "Kanonenplatz PER\n",
      "Einzeln PER\n",
      "Tarsus PER\n",
      "Scheich PER\n",
      "dem PER\n",
      "Kaimakam PER\n",
      "von PER\n",
      "Baalbek PER\n",
      "Marschsicherungen PER\n",
      ". PER\n",
      "Browning PER\n",
      "ringsum PER\n",
      "Scheich PER\n",
      "Karl PER\n",
      "May PER\n",
      ", PER\n",
      "Scheich PER\n",
      "Scheich PER\n",
      "Scheich PER\n",
      "Festessen PER\n",
      "“ PER\n",
      "Scheich PER\n",
      "Hnssin PER\n",
      "Abraham PER\n",
      "Mastix PER\n",
      "Scheich PER\n",
      "Scheich PER\n",
      "Abendland PER\n",
      "“ PER\n",
      "Scheich PER\n",
      "Hussin PER\n",
      "Scheich PER\n",
      "Scheich PER\n",
      "Amanus PER\n",
      "Sven PER\n",
      "Hedin PER\n",
      "Basar PER\n",
      ". PER\n",
      "Kino PER\n",
      "“ PER\n",
      "begönne PER\n",
      "Damen PER\n",
      "“ PER\n",
      "Mandoline PER\n",
      "Augenklappern PER\n",
      "Nie PER\n",
      "Durchgang PER\n",
      ". PER\n",
      "Begleiter PER\n",
      ". PER\n",
      "Stumm PER\n",
      "un- PER\n",
      "  PER\n",
      "willkürlich PER\n",
      "allgemach PER\n",
      "Sonnenzelten PER\n",
      "Karl PER\n",
      "May PER\n",
      "Tausenden PER\n",
      "von PER\n",
      "Jahren PER\n",
      "Allah PER\n",
      "Tscham PER\n",
      "Alan PER\n",
      "Ns- PER\n",
      "laria PER\n",
      "ti-opioa PER\n",
      "Tscham PER\n",
      "Alan PER\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "\n",
    "    if token.ent_type_ == 'PER':\n",
    "       print(token, token.ent_type_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e81c3515-5674-4f5e-bfae-d0a95aa65e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n ', ' ', ',', '.', ':', '>', 'Abendland', 'Abraham', 'Alan', 'Alexander', 'Allah', 'Also', 'Amanus', 'Augenklappern', 'Baalbek', 'Bad', 'Barbarossa', 'Basar', 'Befesti', 'Begleiter', 'Bienenkörbe', 'Birseba', 'Blendender', 'Bouillon', 'Browning', 'Bulgarisch', 'Buuardschik', 'Christus', 'Damen', 'Decka', 'Dera', 'Durchgang', 'Einzeln', 'Eskischekir', 'Festessen', 'Friedrich', 'Geburtskirche', 'Goltz', 'Gottfried', 'Grabe', 'Große', 'Großen', 'Gülek', 'H.', 'Han', 'Hans', 'Hauptmann', 'Hedin', 'Hell', 'Hermon', 'Herrn', 'Himmels', 'Hnssin', 'Hussin', 'Ibrahim', 'Jahren', 'Jahrtausendelang', 'Jakobs', 'Jesus', 'Jslahie', 'Jungfrau', 'K', 'K.', 'Kaimakam', 'Kamelkarawanen', 'Kana', 'Kanonenplatz', 'Karl', 'Kino', 'Konstantinopel', 'Kurs', 'Landfuhrwerke', 'Ma-', 'Mamure', 'Mandoline', 'Maria', 'Marschsicherungen', 'Mastix', 'May', 'Mondaufgang', 'Motorpflug', 'Mücke', 'Nie', 'Nisch', 'Ns-', 'Paschas', 'Paulus', 'Pußta', 'R.', 'Rebekkas', 'Rückreise', 'Sauls', 'Sch', 'Scheich', 'Schmuck', 'Schneid', 'Schroff', 'Schöner', 'Sohn', 'Sonnenschein', 'Sonnenzelten', 'Stumm', 'Sven', 'Szegedin', 'Tarsus', 'Tausenden', 'Tepe', 'Towsend', 'Tscham', 'Tschan', 'Tunnel', 'W.', 'Wau', 'Weiber', 'Xenophon', 'Zögernd', 'ablaufen', 'allgemach', 'at', 'begönne', 'ben', 'dem', 'der', 'des', 'geboren', 'gefährlichem', 'in', 'laria', 'mure', 'ringsum', 'ti-opioa', 'un-', 'v.', 'ver', 'von', 'wau', 'will', 'willkürlich', 'zeichnen', 'zusammentraf', '’', '’s', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "pers_set = { str(token) for token in doc  if token.ent_type_ == 'PER' } # data type is set\n",
    "#pers_list = list(pers_set)\n",
    "print(sorted(pers_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "91b3096e-76e8-4de7-bae2-e3c69ca32af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' \\n', ')', ',', '.', '15', '3800', ':', 'Abraham', 'Adana', 'Adrianopel', 'Ain', 'Alan', 'Aleppo', 'AlexandreM', 'Alexandrien', 'Alexinac', 'Aley', 'Altstadt', 'Amanns', 'Amanus', 'Amara', 'Antilibanon', 'Anziehendste', 'Araber', 'Arbata', 'Arisch', 'Arus', 'Asien', 'Asten', 'Au', 'Audja', 'Ausficht', 'Ausläufer', 'Baalbek', 'Bacchustempel', 'Bagdad', 'Bagdad-Bahn', 'Bagdadbahn', 'Bagrdam', 'Bahn', 'Bahnhof', 'Bahu', 'Balkan', 'Balkanzug', 'Balkanzuges', 'Barada', 'Basalt-', 'Baul', 'Beete', 'Beirut', 'BekÄa', 'Belgrad', 'Berg', 'Berlin', 'Berlin-Schöneberg', 'Besichtigun', 'Bethanien', 'Bethlehem', 'Bezirk', 'Birseba', 'Birseba—', 'Bithynien', 'Bogas', 'Bosporus', 'Bourgas', 'Bozanti', 'Brand', 'Brandstelle', 'Brunnenanlage', 'Brusthöhe', 'Brücke', 'Budapest', 'Bulgare', 'Bulgarien', 'Bund', 'Bundeslade', 'Burghof', 'Chabur', 'Cölesyrien', 'Dagh', 'Damaskus', 'Damaskus-Alep', 'Damaszener', 'Dardanellengefechten', 'Deika', 'Deutschland', 'Diar-bekir', 'Dicke', 'Donau', 'Dorfausgang', 'Dschebel', 'Dschemmin', 'Dschendem', 'Dscherabis', 'Ebbe', 'Ebene', 'Ehrenkompagnie', 'Eisenrohrleitung', 'Eldji', 'Engländer', 'Entente', 'Erde', 'Eregli', 'Erholungsheim', 'Eskischekir', 'Essen', 'Euphrat', 'Europa', 'Europäer', 'Fahrt', 'Fast', 'Feme', 'Festung', 'Feuerstellung', 'Flußbettes', 'Galata', 'Galiläa', 'Garten', 'Gartenmauer', 'Gasanstalt', 'Gaßmann', 'Ge', 'Gebirge', 'Genezareth', 'Geographie-Unterricht', 'Geratewohl', 'Gerste', 'Goldene', 'Golf', 'Grabeskirche', 'Grabesstein', 'Grande-Kanal', 'Grenze', 'Grenzstation', 'Große', 'Großherrlichen', 'Gärtchen', 'Görlitzer', 'Güleck', 'Gülek', 'Hafir', 'Haidar-Pascha', 'Haifa', 'Haiwabs', 'Halbinsel', 'Hama', 'Han', 'Haroün', 'Hasana', 'Hauptausgangspunkt', 'Hauptbahnhof', 'Hauptgebirgsstocks', 'Hauran', 'Hebron', 'Hebrons', 'Hedjas-Bahn', 'Heeresstraße', 'Helal-', 'Helal-Gebirge', 'Heliopolis', 'Hermon', 'Himmel', 'Hirschberg', 'Hirse', 'Hit', 'Holland', 'Holz', 'Homs', 'Horn', 'Hosengurt', 'Hotel', 'Häraun', 'Häusermassen', 'Höhe', 'Höhle', 'Hökesche', 'Iin', 'Isaaks', 'Jaffa', 'Jarmuk', 'Jarmuk-Tal', 'Jarmuktal', 'Jelek', 'Jerusalem', 'Jlek-Gebirge', 'Jordan', 'Jslahie', 'Jsmid', 'Judäa', 'Jupitertempel', 'Jägerstraße', 'Kadihöh', 'Kaffeehäuser', 'Kairo', 'Kaiserhoch', 'Kalk', 'Kanal', 'Kanonenplatz', 'Kapernaum', 'Karmel-Gebirge', 'Katia', 'Kawakli', 'Kidron-Tal', 'Kiel', 'Kilikische', 'Kleinasien', 'Kneipe', 'Knieholzstauden', 'Ko', 'Kocher', 'Kolonnenfahrten', 'Konak', 'Konia', 'Konstantinopel', 'Konstantinopels', 'Kragujevac', 'Kriegsbrücke', 'Kubbet', 'Kunetra', 'Kunststraße', 'Kuppel', 'Kurub', 'Kuseime', 'Kut', 'Kuwek', 'Kydnos', 'Káradscha', 'Köprü', 'Küste', 'Lager', 'Land', 'Landschaftsbilder', 'Lavasteingeröll', 'Lavaströme', 'Lebens-', 'Leine', 'Libanon', 'Libanonberge', 'Lobspruch', 'Lokalzüge', 'Länge', 'Lüls', 'Machpela', 'Machra', 'Magdaba—El', 'Makn', 'Mamure', 'Mann', 'Marava', 'Marmarameer', 'Marmarameeres', 'Mauer', 'Maän', 'Mballah', 'Medina', 'Meer', 'Mekka-Pilger', 'Mesopotamien', 'Mesopotamiens', 'Meter', 'Militärtrans-', 'Missis', 'Mittelmeer', 'Moda', 'Morawa', 'Morgenlandes', 'Morija', 'Moschee', 'Mossul', 'Mousa', 'Musalla', 'Muslimije', 'Muzerib', 'Mädchen', 'Mük', 'Nabulus', 'Nachts', 'Nazareth', 'Nebenbalkonen', 'Nebenerkundungen', 'Nebi', 'Neckartal', 'Nisch', 'Nischawa', 'Nordländer', 'Nordmesopotamien', 'Nosairier-Gebirge', 'Nu', 'Oderberg', 'Oleander', 'Omar-Moschee', 'Operationsbedingungen', 'Orient', 'Orontes', 'Orontestal', 'Ortes', 'Osmaniö-Moschee', 'Ostabhang', 'Ostbahn', 'Palästina', 'Parterre', 'Paßstraße', 'Pera', 'Pera-Palast-Hotel', 'Peterwardein', 'Petroleumbohrturm', 'Pferd', 'Philippopel', 'Phönizische', 'Phönizischen', 'Platz', 'Polenfeld', 'Port', 'Porte', 'Posenschen', 'Potsdam', 'Potsdamer', 'Prinzeninseln', 'Provinz', 'Radjon', 'Ras-Baalbek', 'Raselein', 'Rayak', 'Rhodope', 'Riesengebirge', 'Rote', 'Ruine', 'Rybno', 'Römer', 'Sacktücher', 'Safed', 'Said', 'Salbungsstein', 'Salzgebiet', 'Samaria', 'Sandbergen', 'Sarahs', 'Save', 'Schad', 'Schichtgestein', 'Schl', 'Schlesiens', 'Schneegrenze', 'Schusterahle', 'Schöneberg', 'See', 'Sehweite', 'Semlin', 'Serbien', 'Siegesdenkmal', 'Simons-Fische', 'Sinai', 'Sinai-', 'Sinai-Halbinsel', 'Sliwnitza', 'Sofia', 'Sonnenaufgang', 'Sor', 'Stadt', 'Stambul', 'Stapelplatz', 'Stein', 'Steingeröll', 'Stephans-Tor', 'Strandteil', 'Strauchdieben', 'Straße', 'Städtle', 'Suez', 'Suez-Expedition', 'Suez-Kanal', 'Sultanspalast', 'Syrien', 'Szegcdin', 'Szegedin', 'Szoreg', 'Szöreg', 'Südwestböen', 'Tal', 'Tands', 'Tanrns', 'Tanrusstrecke', 'Tarsus', 'Tatra', 'Taurus', 'Tauruskette', 'Tempelplatz', 'TepZ', 'Teutschlands', 'Theater', 'Tiberias', 'Tich', 'Tigris', 'Tochter', 'Torgebäudes', 'Torpedoloch', 'Tote', 'Tripolis', 'Tscham', 'Tskir', 'Tunnel', 'Turm', 'Türke', 'Türkei', 'Ufer', 'Ungarn', 'Venedig', 'Venustempel', 'Verbindungsrinne', 'Verkehrs-Offiziers', 'Via', 'Vorbereitung', 'Wadi', 'Wadis', 'Wagen', 'Walnußalleen', 'Wand', 'Wasser', 'Wassersahrt', 'Weg', 'Weiterfahrt', 'Weizen', 'Werder', 'Westjordanland', 'Wien', 'Wüste', 'Wüstenberge', 'Zebedmn', 'Zug', '^', 'alt', 'am', 'arabisch', 'asiatisch', 'be-', 'bei', 'bulgarische', 'danken', 'der', 'deutsch', 'dolorosa', 'durchfahren', 'durchfließen', 'durchgehen', 'durchtost', 'el', 'entlang', 'fangen', 'gelegen', 'genießen', 'hoch', 'hörlich', 'i.', 'ich', 'lichen', 'nebelgrauer', 'ost', 'passen', 'regelrecht', 'russisch', 'schaft', 'schieben', 'sich', 'stch', 'straße', 'türkisch', 'unterrichten', 'vereinen', 'vielumkämpften', 'von', 'wohnbaren', 'wölben', 'zudringen', 'zur', 'zweit', 'Ägypten', 'Ärbata', 'Ölberg', 'Österreich', 'öder', '’']\n"
     ]
    }
   ],
   "source": [
    "place_list = { str(token.lemma_) for token in doc  if token.ent_type_ == 'LOC' }\n",
    "print(sorted(place_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3afda-c6e2-4985-9516-fd8eb753cde1",
   "metadata": {},
   "source": [
    "# Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ea40178-b0ae-404f-af50-246e9d959bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d144aae8-7d1a-4948-9a35-f5da32807258",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc_sample_file, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb1a36-800f-48cc-8d23-469df411717e",
   "metadata": {},
   "source": [
    "# Count entities\n",
    "\n",
    "- return everything as list\n",
    "- count list with `list.count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0c36ac56-4382-40e8-aa2b-9e02994d1fab",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3306520044.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/84/2v35331s5t97w8g_wvsp4nv80000gq/T/ipykernel_32054/3306520044.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    [list(for token in doc)]\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "child_list = [list(token.children) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cf17429b-6f18-4bfe-972f-49f7071a21ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.token.Token' object has no attribute 'doc_sample_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/84/2v35331s5t97w8g_wvsp4nv80000gq/T/ipykernel_32054/3939763364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_sample_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.token.Token' object has no attribute 'doc_sample_text'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951763b1-7d6e-4277-be60-b4b5f6f437be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
